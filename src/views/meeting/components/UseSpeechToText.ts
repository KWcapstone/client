import "regenerator-runtime";
import SpeechRecognition, {
  useSpeechRecognition,
} from "react-speech-recognition";
import { useState, useRef, useCallback, useEffect } from "react";

const pickMimeType = () => {
  const candidates = [
    "audio/webm;codecs=opus",
    "audio/webm",
    "audio/mp4", // Safari ê³„ì—´
    "audio/ogg;codecs=opus",
    "audio/ogg",
  ];
  for (const t of candidates) {
    if ((window as any).MediaRecorder?.isTypeSupported?.(t)) return t;
  }
  return ""; // ë¸Œë¼ìš°ì €ê°€ ì•Œì•„ì„œ ê³ ë¦„
};

const UseSpeechToText = () => {
  const { transcript, listening, finalTranscript, resetTranscript } =
    useSpeechRecognition();

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const chunksRef = useRef<BlobPart[]>([]);

  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [audioUrl] = useState<string | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);

  const start = useCallback(async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    streamRef.current = stream;

    const mimeType = pickMimeType();
    const mr = new MediaRecorder(stream, mimeType ? { mimeType } : undefined);

    chunksRef.current = [];
    mr.ondataavailable = (e) => {
      if (e.data && e.data.size > 0) chunksRef.current.push(e.data);
    };
    mr.onstop = () => {
      const type = mr.mimeType || "audio/webm";
      const blob = new Blob(chunksRef.current, { type });
      setAudioBlob(blob);
      chunksRef.current = [];

      // ğŸ”’ íŠ¸ë™ ì •ë¦¬ëŠ” onstop ì´í›„ì—
      streamRef.current?.getTracks().forEach((t) => t.stop());
      streamRef.current = null;
      mediaRecorderRef.current = null;
    };

    mediaRecorderRef.current = mr;
    mr.start(); // timeslice ì—†ì´: stop ì‹œì ì— í•œë²ˆì— ìˆ˜ì§‘
    SpeechRecognition.startListening({ language: "ko-KR", continuous: true });
    setIsRecording(true);
    setIsPaused(false);
  }, []);

  const toggleListening = async (onStopCallback?: (blob: Blob) => void) => {
    if (isRecording) {
      setIsRecording(false);
      // âœ… ë°˜ë“œì‹œ mediaRecorder.stop() ë¨¼ì € í˜¸ì¶œ (onstop ìœ ë„)
      const mr = mediaRecorderRef.current;
      if (mr && mr.state !== "inactive") {
        mr.addEventListener(
          "stop",
          () => {
            if (onStopCallback && audioBlob) onStopCallback(audioBlob);
          },
          { once: true }
        );
        mr.stop();
      }

      // ìŒì„± ì¸ì‹ë„ ì •ì§€
      SpeechRecognition.stopListening();

      // abortëŠ” ì˜ˆì™¸ ì‹œì—ë§Œ ì‚¬ìš© ê¶Œì¥. ì—¬ê¸°ì„  ë¶ˆí•„ìš”.
      // SpeechRecognition.abortListening();

      setIsPaused(false);
    } else {
      await start();
    }
  };

  const stopAndGetBlob = (): Promise<Blob> =>
    new Promise<Blob>((resolve, reject) => {
      try {
        const mr = mediaRecorderRef.current;

        console.log("[stopAndGetBlob] mr:", mr, "state:", mr?.state);
        console.log(
          "[stopAndGetBlob] chunks:",
          chunksRef.current.length,
          "audioBlob:",
          audioBlob?.size
        );

        if (!mr) return reject(new Error("MediaRecorder not initialized"));
        if (mr.state === "inactive") {
          // ì´ë¯¸ ë©ˆì¶°ìˆìœ¼ë©´, ë§ˆì§€ë§‰ stateì— ë‚¨ì€ blobì´ ìˆìœ¼ë©´ ì‚¬ìš©
          return audioBlob && audioBlob.size
            ? resolve(audioBlob)
            : reject(new Error("Recorder inactive and no buffered audio"));
        }

        // ì¢…ë£Œ ì§ì „ ë‚¨ì€ ë²„í¼ë¥¼ ê°•ì œë¡œ ë°€ì–´ë‚´ê¸° (ì¼ë¶€ ë¸Œë¼ìš°ì €ì—ì„œ ì•ˆì „)
        try {
          mr.requestData?.();
        } catch {}

        const localChunks: BlobPart[] = [];
        const onData = (e: BlobEvent) => {
          if (e.data && e.data.size > 0) localChunks.push(e.data);
        };
        const onStop = () => {
          mr.removeEventListener("dataavailable", onData as any);
          mr.removeEventListener("stop", onStop as any);
          const type = mr.mimeType || "audio/webm";
          const blob = new Blob(
            localChunks.length ? localChunks : chunksRef.current,
            { type }
          );
          // ìƒíƒœì—ë„ ë°˜ì˜í•´ë‘ë©´ ì¢‹ìŒ (ì„ íƒ)
          setAudioBlob(blob);
          // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
          streamRef.current?.getTracks().forEach((t) => t.stop());
          streamRef.current = null;
          mediaRecorderRef.current = null;
          resolve(blob);
        };

        mr.addEventListener("dataavailable", onData as any);
        mr.addEventListener("stop", onStop as any);

        // ì‹¤ì œ ì •ì§€ íŠ¸ë¦¬ê±°
        mr.stop();
        SpeechRecognition.stopListening();
        // abortListening()ëŠ” ë³´í†µ í•„ìš” ì—†ìŒ. (ê°•ì œ ì¤‘ë‹¨ ì‹œë§Œ)
        // setRecording/setPaused ê°±ì‹ ì€ onstop ì´í›„ë‚˜ ì—¬ê¸°ì„œ í•´ë„ ë¬´ë°©
        // setIsRecording(false); setIsPaused(false);
      } catch (e) {
        reject(e as any);
      }
    });
  const pauseRecording = () => {
    const mr = mediaRecorderRef.current;
    if (mr && isRecording && !isPaused && mr.state === "recording") {
      mr.pause();
      SpeechRecognition.stopListening();
      setIsPaused(true);
    }
  };

  const resumeRecording = () => {
    const mr = mediaRecorderRef.current;
    if (mr && isRecording && isPaused && mr.state === "paused") {
      mr.resume();
      SpeechRecognition.startListening({ language: "ko-KR", continuous: true });
      setIsPaused(false);
    }
  };

  useEffect(() => {
    return () => {
      // ì–¸ë§ˆìš´íŠ¸ ì•ˆì „ ì •ë¦¬
      try {
        if (
          mediaRecorderRef.current &&
          mediaRecorderRef.current.state !== "inactive"
        ) {
          mediaRecorderRef.current.stop();
        }
      } catch {}
      streamRef.current?.getTracks().forEach((t) => t.stop());
    };
  }, []);

  return {
    transcript,
    listening,
    finalTranscript,
    resetTranscript,

    isRecording,
    isPaused,

    audioUrl,
    audioBlob,

    toggleListening,
    pauseRecording,
    resumeRecording,

    // ğŸ‘‡ ì»´í¬ë„ŒíŠ¸ì—ì„œ í™•ì‹¤íˆ Blobì„ ë°›ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©
    stopAndGetBlob,
  };
};

export default UseSpeechToText;
